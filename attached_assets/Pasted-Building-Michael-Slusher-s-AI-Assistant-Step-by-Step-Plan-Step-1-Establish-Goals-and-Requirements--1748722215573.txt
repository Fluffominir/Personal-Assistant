Building Michael Slusher’s AI Assistant: Step-by-Step Plan
Step 1: Establish Goals and Requirements
Define the assistant’s scope and objectives clearly. Start by outlining exactly what Michael needs from this AI assistant in both personal and professional contexts. Identify all key tasks and pain points (e.g. managing ADHD-related distractions, coordinating creative projects) and map them to features:
Personal Goals: Streamline daily routine, remind about tasks, track habits/health, and provide motivational or mental health support. The assistant should help maintain schedules and well-being.
Professional Goals: Automate project admin (emails, scheduling, updating Notion/Dubsado), organize past work and SOPs, and facilitate team communication. It must understand Rocket Launch Studio’s operations, clients, and workflows.
Integration Targets: List all tools to integrate – Gmail, Google Calendar, Notion, Dubsado (CRM/workflows), QuickBooks (finances), Slack (team comms), Zoom (meetings), Frame.io (video reviews), plus any automation platforms (Zapier/Make) and device ecosystems (Apple’s devices, Apple Watch).
Multi-Modal Access: Decide how users will interact (text chat, voice commands, and a visual dashboard on MacBook, iPhone/iPad, Apple Watch). Define core use cases for each mode (e.g. voice for quick queries or hands-free use, dashboard for overview and configuration).
Privacy/Security Requirements: Note the sensitive nature of personal and financial data. The assistant must handle data securely (encrypted storage, secure APIs) and never act without consent on critical operations. Defining these requirements upfront will guide design choices in later steps.
Step 2: Design the System Architecture
Choose an AI platform and overall architecture for the assistant that balances power, privacy, and scalability:
AI Engine: Select a large language model backend. Options include using OpenAI GPT-4 via API or a fine-tuned open-source model (like LLaMA 2 or GPT-NeoX) hosted privately. GPT-4 is state-of-the-art as of 2025, offering excellent reasoning and understanding
asksensay.medium.com
, while open-source models can run locally for privacy (with possibly reduced capability). A hybrid approach is ideal: use a cloud LLM for complex reasoning, but keep a local lightweight model for ultra-sensitive data or offline tasks.
Retrieval & Memory: Plan for a Retrieval-Augmented Generation (RAG) architecture so the assistant can use Michael’s own knowledge base. This means storing personal docs, SOPs, notes, etc. in a searchable database or index (e.g. a vector database like Chroma or Pinecone) and fetching relevant snippets to provide grounded answers
asksensay.medium.com
. RAG ensures the assistant stays up-to-date and factually accurate about Michael’s life and business by pulling in recent notes or documents on demand.
Tool Integration Layer: The system should include an integration layer allowing the AI to call various tool APIs. As of 2025, new frameworks make this easier. For example, OpenAI’s function calling or “Agents SDK” can let the AI invoke specific tool APIs when needed. Third-party platforms (Zapier, Make, n8n) can also act as brokers for these actions. The architecture might involve a central orchestrator (a custom Python/Node.js server using frameworks like LangChain or Zapier Interfaces) that receives AI requests and executes tool APIs.
Interface Layer: Decide on interface components for chat, voice, and dashboard. For instance, a web or mobile app (built with a cross-platform framework like React Native or SwiftUI) can serve as the chat interface and dashboard. Voice integration might use a speech-to-text service (e.g. OpenAI’s Whisper or iOS Speech Framework) and text-to-speech (Apple’s AVSpeechSynthesizer or Amazon Polly) to enable conversations. Plan how these interface components communicate with the AI backend (likely via secure API calls to the orchestrator).
Data Storage and Processing: Identify where data will live. Likely, a combination of cloud and local storage (for privacy) will be used. For example, personal journals or health data might remain on-device or in iCloud/Notion, whereas anonymized embeddings of documents can live in a secure cloud DB for fast search. All sensitive data (credentials, personal info) must be encrypted at rest and in transit.
Step 3: Integrate Communication & Calendar Tools
Connect the assistant with Gmail and Google Calendar first, as they are key to time management and communication:
Gmail Integration: Use the Gmail API (via Google’s OAuth 2.0) to grant read/write access to Michael’s inbox. The assistant should be able to read emails, parse content, draft responses, and flag important messages. For example, new email triggers can send the content to the AI for summarization or action. (Using Zapier is one approach: configure a Gmail trigger “New Email” and have it send the email text to the assistant for processing
linkedin.com
.) Ensure only non-sensitive info or summaries are fed into the LLM to protect privacy.
Calendar Integration: Connect Google Calendar API to fetch events, create or modify events, and get reminders. The assistant can generate daily agendas each morning, schedule new meetings, and warn of conflicts. In Zapier, one might set a trigger for “Event Start” or new events and funnel those details into the AI to compose a natural-language agenda or smart reminder
linkedin.com
. Conversely, when the user asks to schedule something, the assistant can use a calendar API call to find open slots and create an event.
Email Management Features: Implement intelligent filtering/prioritization. For instance, the assistant can highlight urgent emails (perhaps based on sender or keywords like “Invoice” or client names) and even draft replies. Always have drafts or suggestions go to Michael for approval before sending to avoid mistakes. This human-in-loop outbound email ensures no unintended messages are sent without review.
Scheduling & Reminders: Use the combined email and calendar data to create a smart reminder system. The assistant could send a Slack DM or phone notification for important upcoming events or tasks. It might also schedule focus time by analyzing calendar gaps. Because Michael is neurodivergent (ADHD), consider more frequent nudges and time-blocking. E.g., “Your next meeting is in 10 minutes, time to start wrapping up current task,” or midday check-ins if no calendar events (to ensure he hasn’t lost track of time).
Multi-account Consideration: If Michael uses separate accounts (personal Gmail vs business G Suite), integrate both. The assistant should distinguish contexts (personal vs work) and treat data appropriately (e.g. don’t expose client emails during personal time). This may involve separate API credentials and tagging the data coming from each.
Step 4: Integrate Knowledge and Project Management Systems
Connect Notion, Dubsado, QuickBooks, Slack, Zoom, Frame.io, and any other business tools to give the AI a 360° view of Michael’s professional world:
Notion Integration: Notion houses notes, SOPs, project plans, etc. Utilize the Notion API to query pages or databases. For example, the assistant should retrieve SOP documents or gear inventories from Notion when asked (“What’s our SOP for client onboarding?”) and even update Notion pages (like logging meeting notes or new ideas). You can store important reference content in a Notion knowledge base that the assistant searches via the API. This effectively makes Notion a structured “external memory” for the AI.
Dubsado Integration: Dubsado likely contains client CRM data, contracts, workflows (popular for creative businesses). Check if Dubsado offers an API or use automation (Zapier/Make) to pull info. The assistant might retrieve a client’s status, contract dates, or pending invoices from Dubsado. For instance, if Michael asks, “When is Client X’s payment due?” the assistant can query Dubsado and respond with the invoice status. It can also update workflows: e.g., when a project phase is marked complete in Notion, the assistant triggers a Dubsado workflow update via Zapier.
QuickBooks Integration: Financial data is sensitive, so integrate QuickBooks carefully via their API (using OAuth). The assistant could fetch revenue numbers, recent expenses, or generate summaries like “This week’s cash flow is X.” However, avoid sending raw financial data to the LLM. Instead, do computations locally or on a secure server, and have the AI explain or give advice on the results. For example, the system might calculate that Q2 revenue is 10% down from Q1 then prompt the AI to suggest reasons or actions, referencing only the high-level stats (keeping raw data secure).
Slack Integration: Create a Slack bot for the assistant to interface with Michael and possibly the team. Through Slack’s API, allow the assistant to post in specific channels or DM Michael. Use cases: deliver daily agendas via Slack each morning, remind about tasks, or even answer team questions by pulling from SOP docs (with caution and only with authorized info). Ensure the bot only posts what Michael permits – e.g., it could prepare a draft message to a team channel summarizing a meeting, which Michael can review and send. Slack is also useful for approvals – for instance, Zapier has a Slack approval step that pauses automation until a person approves
zapier.com
. Implement such approval flows for any sensitive automated actions.
Zoom Integration: Leverage Zoom’s API or Zapier integration to access meeting info. The assistant can retrieve meeting transcripts or recordings (Zoom can provide transcripts if cloud recording is on) and then summarize them. After a client call, the assistant might generate a brief of decisions and action items and log it to Notion or Slack. Stretch goal: Have the assistant join meetings as a silent participant by using Zoom’s API or an SDK – it could transcribe in real-time and highlight tasks. At minimum, scheduling Zoom meetings via the Calendar integration and sending Zoom links to attendees (perhaps via Gmail or Slack) should be automated.
Frame.io Integration: As a video review platform, Frame.io holds client feedback on videos. Check for Frame.io API access. The assistant could pull comments from Frame.io and compile a to-do list for video edits. For example, “Frame.io: Client X commented ‘Scene 3 too dark’ – add to revision list.” By integrating this, Michael won’t miss client feedback – the assistant can surface it and even update a task in Notion (“Brighten scene 3 per client feedback”). Automation via Zapier or Make can help here (Frame.io triggers on new comment -> sends to assistant for processing).
Unifying These Integrations: It’s wise to centralize API calls through the orchestrator. For instance, using a library or framework that defines “tools” for the AI (email_tool, notion_tool, etc.). Modern agent frameworks let LLMs call these tools in sequence
medium.com
. OpenAI’s function calling or Agents SDK can parse the AI’s output to know which tool to invoke
credo.ai
credo.ai
. For example, if the user says “Update the project status for Client Y and email them the summary,” the AI might internally decide: 1) call notion_tool to update a page, 2) call gmail_tool to draft an email. The orchestrator captures these intentions and performs them via the relevant integration. Using such an approach (e.g. the Smithery MCP servers mentioned in a recent tutorial
medium.com
) avoids writing boilerplate for every service and makes adding new tools easier.
Step 5: Develop the Multi-Modal User Interfaces
Create user-friendly interfaces for text, voice, and visual interaction so Michael can use the assistant seamlessly across devices:
Chat Interface (Text): Build a chat UI for typing and reading responses. This could be a web app or native mobile app. Ensure it supports message history, link previews (for retrieved documents or references), and rich formatting (so the assistant can output lists, code blocks, etc., as Markdown which your UI renders). The chat UI should be accessible on Mac (perhaps as a desktop app or simply via browser) and on iPhone/iPad (mobile-responsive or native app). Using a framework like React Native or Electron can allow reuse of code across desktop and mobile. Keep the interface clean and focused – an input box and a scroll of conversation, with options to attach files or pick voice input.
Voice Interface: Implement speech-to-text and text-to-speech for hands-free operation. On Apple devices, you can utilize built-in Siri Shortcuts or the Speech framework. For example, create a Shortcut that when invoked (via Siri or a tap on Apple Watch) will start listening and send the transcribed query to the assistant, then read out the answer. Alternatively, integrate a third-party service: the OpenAI Whisper model (or API) can accurately transcribe voice to text, and services like ElevenLabs or Amazon Polly can produce natural speech replies. Aim for a near-real-time response so it feels conversational. Also, ensure voice interactions respect privacy – e.g., only actively listen after an explicit command.
Dashboard (Visual Overview): Design a dashboard that provides a bird’s-eye view of Michael’s day and systems. This could be a tab in the chat app or a separate web portal. Key elements might include: Today’s agenda (calendar events, top tasks), pending reminders, recent emails or Slack mentions, and KPIs like number of open projects or unread messages. Essentially, this dashboard aggregates information the assistant is monitoring. Michael’s Apple Watch can receive summarized notifications from this (e.g., via an iOS app companion or just mirrored iPhone notifications). The dashboard might also offer controls: toggling certain automations on/off, adjusting preferences (like “don’t disturb me in focus mode” or “send me motivational quotes daily”).
Cross-Device Sync: Use cloud sync (or a backend server) to ensure that whether Michael uses the Mac, phone, or watch, the assistant’s state is consistent. Conversations started on the Mac should be viewable on the iPhone. Notifications should not double-fire on all devices – manage them intelligently (possibly integrate with Apple’s notification center to respect focus modes).
User Experience for Neurodivergence: Since Michael has a neurodivergent workflow, make the UI flexible and not overwhelming. Provide information in clear, digestible chunks. Maybe allow visual cues like color coding for urgency, or gamified elements (e.g., showing progress bars for daily goals). The voice tone can be supportive and calm. These design touches can make the assistant more engaging and helpful for someone with ADHD (for example, using a friendly tone to redirect focus when distracted, rather than a sterile alert).
Step 6: Implement Personal Support Features
Build out the features that assist Michael in his personal life and self-management:
Task and Routine Management: Incorporate a task list (perhaps pulling from Notion or Reminders app) that the assistant can manage. Michael should be able to tell the assistant “Add task to water the plants every Tuesday” or “What’s on my to-do list today?” and get appropriate responses. The assistant can use Notion or Apple Reminders as a backend for tasks, updating it via API. Utilize recurring tasks and routine templates – e.g., if Michael has a morning routine, the assistant can guide him through it each day. It could check off items as he completes them (either by voice command or automatically if it can detect via calendar that it happened).
Reminders and Alerts: Besides scheduled events, allow ad-hoc reminders: “Remind me in 1 hour to call the client” – the assistant should set a timer or calendar entry and then notify via chosen channel (Slack DM, phone push, etc.). Ensure reminders are context-aware and persist (so if he dismisses on watch, it doesn’t spam phone again). Also, implement intelligent reminders, for example: if an email mentions a deadline date, the assistant could suggest “Do you want to set a reminder for this deadline?”.
Mental Health and Habit Tracking: Integrate with health data and journals to monitor well-being. If Michael uses Apple Watch and the Health app, consider using HealthKit data (with permission). For example, track sleep hours, heart rate variability (stress indicator), exercise, and even the new mental health logging in iOS (mood tracking). The assistant can log daily mood via a quick question (“How are you feeling this morning?”) and track it. With this data, implement simple analytics: “Your mood tends to dip on days when you sleep under 6 hours. Try to get to bed earlier.” or “You reported high stress every Friday – perhaps due to weekly client calls. Consider scheduling a relaxing activity on Friday evenings.” These kinds of feedback loops make the assistant a health coach of sorts. (Indeed, even Apple is reportedly working on an AI health coach agent to do similar analysis
appleinsider.com
.)
Daily/Weekly Agenda and Reflections: Have the assistant generate a personalized daily briefing each morning (via email or Slack message). This could include: today’s events, deadlines coming up, tasks due, and even a motivational quote or a note like “It’s going to rain – don’t forget your umbrella” if weather API is added. At day’s end, it could prompt a short reflection or journal (“What went well today? Any challenges?”) to help Michael build self-awareness. Weekly, it might compile a short review – “This week you completed X tasks and had Y meetings. You met your exercise goal 3/5 days. Consider catching up on the two missed workouts this weekend.” Such summaries encourage positive routines and accountability.
Personalized Feedback and Coaching: Using Michael’s psychological profile (from the personality document and known preferences), program the assistant to tailor its communication. For example, if Michael values direct feedback, the assistant can be straightforward when pointing out issues. If he tends to get overwhelmed, it can break tasks into smaller steps automatically. The assistant should also incorporate encouragement aligned with his interests – e.g., referencing his favorite inspirational quotes or heroes when he needs motivation. Example: If Michael is a fan of a particular movie, the assistant might say “Remember, 'Do or do not. There is no try.' – keep that in mind as you tackle this task!” (drawing from his list of inspirational quotes).
Privacy in Personal Data: For all personal support features, implement strong privacy controls. Health and mood data should be stored securely (possibly only locally on his devices or in encrypted form on a server). If using any cloud AI processing on this data, consider anonymizing it (the assistant might say “user’s mood is low” rather than “Michael is feeling depressed” when sending to the model). Michael should also be able to opt out or erase this personal data any time.
Step 7: Implement Professional Support and Automation Features
Now focus on features for work: helping organize projects, manage content, and streamline team operations. Leverage the integrated tools from Step 4 to build these capabilities:
Knowledge Management and SOP Access: Load all company Standard Operating Procedures (SOPs), reference manuals, gear inventory lists, client FAQs, etc., into the assistant’s knowledge base. This could mean storing them as text embeddings for Q&A retrieval
asksensay.medium.com
 or simply making sure the assistant knows how to query Notion for them. The goal is that Michael (or even team members, if allowed) can ask, “How do we usually handle final invoice for a wedding shoot?” and the assistant will answer based on the documented SOP. Keep these documents updated and let the assistant cite the source when giving answers, so Michael trusts it (for instance, “According to the Rocket Launch Studio SOP doc, final invoices are sent within 48 hours of project completion.”).
Project & Task Updates: Whenever there are changes in one system, propagate to others automatically to reduce manual admin. For example, when a client approves a video in Frame.io, the assistant could mark the task “Edit Video XYZ” as completed in Notion and notify the team on Slack. Use automation tools or custom scripts listening to webhooks for such events. Similarly, if a new project is started in Dubsado (client signed a contract), the assistant might auto-create a project page in Notion and schedule a kickoff meeting on the calendar. These cross-tool updates keep everything in sync. Zapier/Make can be configured for many of these triggers and actions (e.g., new Dubsado project -> call a webhook that the assistant receives, then it uses Notion API to create a page and Slack API to alert the team).
Client Communications: The assistant should help draft and coordinate communications. If a client emails asking for an update, the assistant can pull the latest project status (from Notion or internal notes) and draft a polite, context-rich reply. Michael reviews and sends it, saving time. For recurring communications (monthly newsletters, project status reports), the assistant can generate a template and fill in data (number of tasks done, upcoming milestones) again pulling from project management data. This ensures clients get timely, informative updates with minimal effort.
Team Coordination: Enable the assistant to act as a team coordinator in a limited capacity. For instance, it can monitor Slack for certain keywords or requests like “@assistant schedule meeting” or if someone asks “Where is the link to the onboarding SOP?” – it can jump in with the answer or action. Use caution: this should be opt-in and perhaps only in specific channels or threads to avoid disruption. Another angle is task delegation – if Michael tells the assistant “Remind John to send me the footage by Tuesday,” the assistant can post a reminder to John (either via Slack mention or assign a task in the system) and follow up if not done. Always log these actions so Michael can see what the assistant has asked of others, maintaining accountability.
Automation and AI Actions: For any automated actions, enforce a check or approval mechanism. The assistant might be allowed to do low-risk things on its own (e.g. format a Notion page, sort an email into a folder), but for high-impact tasks (sending an email to a client, moving money in QuickBooks, scheduling a meeting involving others), it should ask for confirmation. This can be as simple as the assistant saying, “I’ve drafted an email to Client X about the delay. Send it?” with a yes/no button for Michael. In some cases, a rule-based approval can apply (e.g., if an invoice amount > $1000, always get approval). By keeping a human-on-the-loop approach, we balance efficiency with safety
credo.ai
. Michael retains ultimate control, preventing the AI from ever going rogue or making unauthorized decisions.
Continuous Learning from Business Data: As projects progress, feed the outcomes back to the AI’s knowledge. If a project was delayed and a retrospective note was written, make sure the assistant can access that next time it plans a schedule. Over time, it will learn typical project durations, client preferences (e.g. Client Y prefers phone calls over emails), and common bottlenecks. This learning can be stored as additional data or fine-tuning. Example: If the assistant notices that “draft video edits usually take 2 weeks but our schedules allocate 1 week,” it could flag that as a process improvement suggestion in the feedback step.
Step 8: Personalize and Continuously Train the Assistant
Give the assistant a sense of Michael’s personality, preferences, and habits, and set up a learning loop so it improves over time.
Import Personal Profile: Utilize the information from Michael’s profile and personality documents. Input key facts into a secure profile database – e.g., working style (night owl vs morning), preferred communication tone, known ADHD coping strategies, important values (creativity, punctuality, etc.), and interests (favorite movies, role models, quotes). Program the assistant’s initial prompt or configuration with these details so it can adopt a fitting tone and approach. For example, if Michael has a humorous style, allow the assistant to use light humor in replies to him to make interactions enjoyable.
Contextual Recommendations: Using the stored preferences, the assistant can tailor suggestions. If it knows Michael values work-life balance, it might suggest “It’s 7 PM, you’ve been working 10 hours – consider winding down.” If it knows he’s inspired by certain entrepreneurs or artists, it might reference their quotes when giving business advice. This makes the advice more relatable and motivating to Michael personally.
Learning from Feedback: Implement a feedback mechanism. Michael should easily give feedback like “That suggestion wasn’t helpful” or “Good job on that email draft.” This could be via quick reactions in the interface (thumbs up/down) or verbally. Use this feedback to adjust the assistant’s behavior. Technically, store the feedback and periodically retrain or fine-tune certain responses. For example, if Michael consistently rejects meeting scheduling on Mondays, the assistant should learn not to propose Monday meetings unless critical. You might retrain a custom model on conversation logs + feedback every few months, or use reinforcement learning techniques to better align with Michael’s expectations.
Updating Knowledge Base: Establish a routine to update the assistant’s knowledge. New documents or company procedures should be ingested (e.g., a new SOP PDF added – index it for search). Personal life changes (new habit tracking app, new health goal) should be synced. Automate this where possible: e.g., a nightly job could sync any new Notion pages or new Google Drive files into the vector database. Continuous learning ensures the AI stays current without manual re-programming.
Limit Forgetfulness: If using an LLM with finite context, mitigate forgetting by designing prompts that always include the most relevant facts about Michael. For instance, a “system prompt” can contain a summary of Michael’s key details (updated as needed). Also, utilize long-term memory stores. By May 2025, frameworks for LLM long-term memory are emerging that let the AI fetch older conversation history or notes when needed rather than relying purely on the last few messages. Implementing this ensures the assistant remembers context from weeks or months ago (e.g., a promise made to follow up on a personal goal) and brings it up appropriately.
Step 9: Ensure Robust Security and Privacy
Implement strong safeguards to protect Michael’s data and prevent misuse. This is critical given the sensitive personal and financial information involved:
Authentication & Access Control: Secure the assistant’s access to each integration with proper OAuth flows and API keys. Never store raw credentials in code. Use a secure vault for secrets. The assistant’s own app/dashboard should be password-protected or use biometric login (since it has access to so much data). Also consider device-based authorization – e.g., only Michael’s devices are allowed to interface with the assistant (to prevent an attacker from impersonating him on a random device).
Data Encryption: All sensitive data stored (personal profile, financial records, health logs, conversation history) should be encrypted at rest. If using cloud storage or a database, enable encryption and consider end-to-end encryption for the most private info (meaning even the server admin can’t read it, only the client app can decrypt). In transit, always use HTTPS and secure WebSocket connections. Never send unencrypted personal data over insecure channels.
LLM Data Handling: Be mindful of what data is sent to the AI model, especially if using a third-party API like OpenAI. OpenAI pledges not to use API data for training by default (as of 2023), but still, minimize sending unnecessary PII. For example, instead of feeding an email with full client contact info, extract the needed context (like “Client asked about X deadline”) and send that for summarization. For an on-premise model, ensure the server is secure and that model outputs can’t be inadvertently leaked.
Tool Action Safety: Implement safety checks in the orchestration layer. For instance, if the AI tries to call the QuickBooks API to move money or delete an invoice, have a rule that blocks it or flags for human approval. We can maintain a whitelist of allowed operations versus high-risk operations. This prevents any possibility of the AI executing destructive commands, whether due to a prompt injection or an error. It’s essentially a permission system for the AI’s tool usage.
Audit Logging: Keep logs of what the assistant does: API calls made, data accessed, messages sent. These logs should be accessible to Michael (perhaps via the dashboard) so he can review the assistant’s actions. Audit logs create transparency – if anything odd happens, it can be traced. They also help in refining the system (seeing where errors occur).
Privacy Settings & Opt-Out: Provide controls to Michael to pause or restrict the assistant’s access at times. For example, a “privacy mode” toggle might temporarily suspend listening on certain accounts or stop collecting health data if he wants a break. Also, make it clear how to wipe data if needed (for instance, deleting all conversation history or revoking the assistant’s access to Gmail can be done via Google’s security settings at any time).
Comply with Regulations: Given the data types involved (health info could fall under HIPAA, financial under various laws), if this system ever extends beyond personal use, ensure compliance with relevant regulations. For personal use, it’s mainly about following best practices – but as a precaution, treating health data with HIPAA-level care (even if not legally required) is a good practice for security.
Step 10: Connect APIs and Automation Workflows
Leverage APIs and automation tools to make the assistant proactive and reduce manual effort. By now, integrations are set up; this step orchestrates them into smooth workflows:
Zapier and Make Workflows: Identify repetitive multi-step processes in Michael’s routine that can be automated. For example: When a new inquiry form is submitted (via Dubsado or website), add it to Notion as a lead, send Michael a Slack alert, and draft a response email. Build a Zap (or Make scenario) for this, with the AI assistant in the loop for any smart text generation. Zapier’s 2024 update even introduced an “Agents” feature that helps create AI-augmented Zaps
zapier.com
. Use these where possible to minimize coding. Make (Integromat) can be a cheaper alternative if many actions are needed. Each workflow should be tested thoroughly to avoid chaos (e.g., ensure we don’t double-create entries or spam clients).
Custom Scripts and Functions: For complex logic that out-of-the-box automation can’t handle, write custom scripts (Python/JavaScript) and host them securely (perhaps as AWS Lambda functions or a small serverless setup). These can do things like: parse a Frame.io JSON payload to extract comments, or perform a QuickBooks query for all unpaid invoices and then return a summary. The AI can call these via a function call interface. Essentially, extend the assistant with bespoke tools for Michael’s unique needs – an example might be a “project_analyzer” function that calculates project delays or resource loads from various systems and provides a summary to the AI.
Email and Slack Automation: Set up filtering rules that forward certain communications to the assistant. For example, auto-forward client emails to a special alias that the assistant monitors, so it can immediately summarize or alert Michael. In Slack, use event subscriptions: if someone tags @Michael in a message, the assistant could catch that and ensure Michael is prompted with the context and a drafted reply (if appropriate). This way nothing slips through the cracks when things get busy.
API Rate Limits & Error Handling: When automating, be mindful of API limits (Google, Slack, etc., all have rate limits). Implement backoff and retries. Also handle outages gracefully – if Google Calendar is down or Zapier hiccups, the assistant should inform Michael of any temporary issue rather than silently failing. It might say “I’m unable to update the calendar right now, but I’ll retry shortly.” This transparency builds trust.
Integration of New Tools: Leave room to integrate more services if needed. For instance, if in future Michael uses a CRM like HubSpot or a task app like Trello, the architecture should allow adding those. With a modular design (each integration as a plugin or API wrapper), adding new ones won’t require a full redesign. The step-by-step approach can be repeated: obtain API access, define triggers/actions, and add to the assistant’s toolkit.
Step 11: Implement Feedback, Optimization, and Insight Features
Enable the assistant to not just automate, but also analyze and advise on improvements – acting like a business analyst and coach. This fulfills the goal of spotting blind spots and optimizing Michael’s operations:
Performance Dashboards: Feed relevant data into an analytics dashboard the assistant can access. For example, track metrics such as turnaround time on projects, number of late deliveries, weekly revenue, number of new leads, etc. The assistant can use these to find trends. A simple way is to maintain a Google Sheet or database with these KPIs updated by automation scripts. The AI can then read from this when generating its weekly reports or suggestions.
Periodic Business Reviews: Program the assistant to produce a weekly or monthly “business health report.” It can include sections on finances (“Income this month is 5% higher than last, driven by X project”), client engagement (“You haven’t followed up with Client Z in 3 weeks”), workflow (“Average project completion time has improved”), and any bottlenecks (“You spent 12 hours on admin work – consider delegating or automating X task”). By comparing against past data and known goals, the assistant can highlight what’s on track or not. This is where the integration of QuickBooks, Dubsado, etc., really comes together – the AI can cross-analyze data from different sources.
Proactive Suggestions: Encourage the assistant to offer suggestions unsolicited (but in a non-intrusive way). For example, if it notices Michael consistently working late, it might suggest hiring an intern or using a new tool to reduce workload. Or if a certain type of project yields better profit, it could suggest focusing marketing on that niche. These suggestions should be delivered in a considerate manner (perhaps in the weekly report or when asked for feedback, rather than constant nagging). Michael can also directly ask, “Do you see any way I can improve my workflow?” and the AI, armed with data, can respond with insightful advice.
Inspiration and Creativity Boosters: The assistant can use Michael’s inspirational materials here. If Michael is in a creative slump or overwhelmed, the assistant might inject a relevant quote or anecdote from his favorite books/movies. For instance, during a tough project it might quote a line about perseverance from a film he loves. This requires having those references stored (perhaps in a Notion page or a simple JSON file of quotes) and tagging them by theme (motivation, focus, humor, etc.). The AI can pull a quote when appropriate to keep the tone uplifting.
AI Self-Optimization: Implement logging of when the assistant’s suggestions or actions were useful vs. ignored. Over time, analyze this (manually or with AI) to refine its strategy. For example, if Michael never acts on the Friday afternoon suggestion to plan next week, maybe the assistant should try a different approach or timing (like Sunday evening). Essentially, treat the assistant as a product that can be optimized: collect user engagement metrics on its features and iterate. Possibly, run A/B tests on certain messages (if feasible with one user – or just trial and observe) to see what style of communication gets the best response from Michael.
Human Oversight in Feedback Loop: While the assistant is providing feedback to Michael, ensure Michael can also easily correct the assistant’s conclusions. If the AI says “Project A is delayed,” and Michael knows it’s actually on track (maybe the data was misleading), he should correct it. The assistant should then adjust its understanding (perhaps update the data store or at least acknowledge the mistake). This keeps trust – Michael should never feel the assistant is making pronouncements without basis or recourse.
Step 12: Test Safeguards and User Control Mechanisms
Before full deployment, rigorously test the system and implement safety nets to ensure the AI behaves as desired.
Simulation Testing: In a controlled environment, simulate various scenarios (both common and edge cases). For example, test how the assistant handles conflicting meeting requests, or an email with ambiguous instructions, or a Slack message with an unfamiliar acronym. Verify it doesn’t produce incorrect or nonsensical actions. Use a staging setup for integrations if possible (e.g., a test Slack workspace or dummy Gmail) to avoid affecting real data during testing.
Approval Workflow Validation: Intentionally trigger actions that require approval and ensure the assistant properly pauses and seeks confirmation. For instance, simulate the assistant drafting a sensitive email or attempting to pay an invoice, and see that it indeed asks Michael before proceeding. If using Slack for approvals, test that integration (Zapier’s Slack approval feature can be handy to pause a Zap until approval
zapier.com
). Make sure an unapproved action simply doesn’t happen and the request doesn’t get lost.
Error Handling: Induce some failures (like revoke the Gmail token to see what happens when it can’t access email, or make an API return an error). The assistant should catch exceptions and inform the user gracefully: e.g. “I’m sorry, I couldn’t access Google Calendar just now. Please check the connection.” This is better than silently failing or flooding with error text. Logging these errors is important so you can fix the root cause.
User Training and Controls: Ensure Michael is comfortable with how to control the assistant. Provide a quick guide (maybe as a Notion page or in-app help) on commands he can use and how to override the AI. For example, teach the phrases or buttons for “cancel that” or “stop listening” or “don’t do that.” Include how to turn off certain automations (like “pause all outgoing emails”). Knowing he has control will make Michael more confident in using the assistant’s powerful features.
AI Behavior Bounds: To prevent the AI from drifting off course (like giving irrelevant advice or oversharing), maintain strict system instructions for the LLM. Test adversarial prompts to be sure – e.g., if someone externally messages the assistant weird requests, does it stay on mission? The assistant should be focused on Michael’s context only. Given it can access tools, also test for prompt injection vulnerabilities (someone might try to get the AI to do something unsafe via a cleverly crafted email). Add filters: if any incoming data or prompt tries to manipulate the AI’s instructions (like “Ignore previous instructions…”), have the system detect and refuse that.
Ethical and Safe Responses: Since the assistant will also converse with Michael about personal issues (mental health, etc.), ensure it follows a helpful, non-biased, and non-harmful approach. It should not provide medical or legal advice beyond its scope. If Michael’s mental health logs indicate severe issues, the assistant should not try to act like a doctor; instead it might gently suggest seeking professional help or using a grounding technique. These guidelines should be part of the AI’s system prompt and tested. Basically, the AI must know its limits.
Step 13: Deployment and Hosting Strategy
Decide where to host the various components for maximum security and reliability, and deploy the system. This step considers the cloud vs local question and cost estimates:
Cloud Hosting (Pros & Cons): Deploying on cloud servers (AWS, Azure, GCP) provides scalability – the assistant’s backend can scale with usage and be accessible from anywhere. For example, an AWS EC2 or Azure App Service can run the orchestrator and integration services, and you might use Azure’s OpenAI service for GPT-4 access (which keeps data within Azure’s compliance boundary). Cloud is convenient but has ongoing costs and trust considerations (you must trust the cloud provider with your data, albeit encrypted). Costs might include: a small server ($20-50/month), vector DB service ($0-**?), and API usage fees for AI (OpenAI GPT-4 can be ~$0.03–$0.06 per 1K tokens; heavy use might be a few hundred dollars a month for constant large prompts). Zapier or Make have subscription fees (Zapier ~$20-50/month for moderate usage
linkedin.com
, or more if many Zaps; Make is cheaper or even free for low volume). QuickBooks API might require a paid tier of QuickBooks. Overall, a cloud-based solution could range from tens to a few hundred dollars per month depending on usage.
Local Hosting (Pros & Cons): Running everything on Michael’s own hardware (e.g., a Mac Studio or a dedicated server) keeps data private and saves on cloud costs, but comes with maintenance and potential limitations. An Apple Silicon Mac can run smaller LLM models reasonably (there are optimized models that could run on a MacBook GPU), but to match GPT-4’s power, you’d need a high-end GPU. Local setup also could be less accessible remotely (unless opening ports or using a VPN). If privacy is paramount, a compromise might be to run the core AI locally (perhaps a fine-tuned 13B or 30B model) for highly sensitive tasks, and only call out to cloud GPT-4 for things that need extra intelligence (and even then send minimal data). The cost here is mostly upfront hardware (a powerful PC with a GPU could be $2000+, or leveraging an existing Mac).
Hybrid Approach: Many real implementations use a hybrid: e.g., run the orchestrator and databases on the cloud, but keep certain data stores local or on-device. Or vice versa: have the orchestrator local and it calls out to cloud only for AI. Evaluate what data must stay private (maybe journal entries, etc., which could be kept local in an encrypted SQLite that the AI references via retrieval) versus what is acceptable in cloud (calendar events or Notion data that are already cloud-based anyway). A hybrid model can also improve reliability – if cloud AI fails, the local model can step in for basic tasks.
Scalability Considerations: Initially, the “user base” is just Michael (and possibly a couple team members if he shares it). But think ahead: if Rocket Launch Studio grows, could this assistant be extended to other employees or even offered as a service? If yes, design the deployment to be multi-user scalable (each user with their own data partitions). Using cloud infrastructure would then be preferable for scalability. If it’s strictly personal, scalability is less about more users and more about handling peak loads (e.g., when lots of automations trigger at once). Cloud functions and queues can help smooth that (ensuring the system doesn’t crash if 10 triggers fire simultaneously).
Deployment Process: Set up a dev/test environment and a production environment. Use containers (Docker) to package the orchestrator and any custom services for easy deployment and rollback. Configure CI/CD if possible, so updates to the assistant (tweaking a prompt or adding a feature) can be deployed with minimal downtime.
Budget Estimates: Summarizing the likely costs, assuming a cloud-heavy approach:
Cloud AI API: $100–300/month (varies by usage, can start lower and scale up with usage).
Integration services (Zapier/Make): $30–100/month (depending on volume of tasks automated).
Hosting (server, DB, storage): $20–50/month for a small VM and perhaps $0-20 for a vector DB or you might use a free tier if small scale.
Voice services: if using third-party TTS or STT, maybe $10–20 if heavy usage (or free if using local iOS capabilities).
These can be optimized (e.g., using Make or n8n self-hosted instead of Zapier to cut cost, or pausing expensive AI calls when not needed). Ensure to set monthly usage alerts on APIs to avoid surprises.
Monitoring and Maintenance: Once deployed, set up monitoring on the system. Use tools to track uptime (Pingdom or even simple cron job that tests each integration periodically). If something fails (like the Gmail token expires), the system should alert Michael with clear instructions to fix (e.g., “Please re-authenticate Gmail access”). Maintenance tasks include updating API keys, applying software updates (especially security patches), and periodically reviewing if the AI model should be updated (in 2025-2026, new versions may come – e.g., GPT-5 or better open models). Plan time for this maintenance or budget if using a developer’s help.
Step 14: Continuous Improvement and Ethical Considerations
Finally, treat this assistant as an evolving project. Schedule regular reviews and updates:
Regular Updates and Iteration: Every few weeks, review how the assistant is performing. Gather notes on any mistakes or inconveniences Michael encountered. For example, maybe the voice recognition mishears certain words – that could be improved by tuning the STT engine or adding those words to a custom vocabulary. Or perhaps the weekly report is too verbose – adjust the prompt to be more concise. Continuously iterating will make the assistant more practically useful over time.
Stay Current with Tech: The AI field is moving fast. As of May 2025, new features are emerging (OpenAI’s tools, Apple’s AI initiatives, etc.). Keep an eye on updates – e.g., Apple may open up more AI abilities in iOS (rumors of a built-in coach in Health as noted) which could be leveraged, or OpenAI might release more agent capabilities that simplify what we custom-built. Be ready to integrate improvements – for instance, if a future Siri update allows third-party AI plugins, Michael’s assistant could tie into Siri more natively.
Ethical AI Use: Ensure the assistant continues to behave within ethical boundaries. It should never be used to do something unethical (like spamming clients, or snooping on employees beyond what’s appropriate). Build in constraints: if Michael asked it to do something questionable (like “find personal info on this person from their email”), the assistant should refuse or at least caution if it violates privacy or laws. Also be mindful of bias – if the AI is giving business advice, it should base it on data and best practices, not any biased training data. Keeping Michael in the loop for decisions helps mitigate this – human judgment remains primary.
User Trust and Control: To keep trust, maintain transparency about what the AI can and cannot do. If there’s a limitation (say, “I can’t access that data” or “I’m not qualified to advise on that”), the assistant should be upfront. Encourage Michael to see the assistant as a helpful partner, not a flawless oracle. By setting that expectation, any mistakes are seen in proper perspective. And always, give Michael the final say – whether it’s sending an email, making a business decision, or adopting a workflow change, the AI provides the options or draft, and Michael confirms. This approach, known as human-on-the-loop, balances efficiency with safety, allowing the AI to function independently in low-risk tasks while keeping human supervision on critical decisions
credo.ai
.
Conclusion: Following this step-by-step plan will result in a powerful, custom AI assistant uniquely tailored to Michael Slusher’s life. It will handle the busywork of communication and coordination, provide intelligent insights into his routines and business, and stay aligned with his personal style and values. By integrating the right tools, maintaining strict security, and keeping the human in control of the loop, the assistant will be practical, scalable, and genuinely supportive of Michael’s neurodivergent workflow and creative professional life – like a tireless sidekick helping him focus on what he does best, with peace of mind that nothing important falls through the cracks.
Citations
Favicon
Implementing a ‘Wisdom Engine’ for Personal Knowledge Management | by Sensay | Medium

https://asksensay.medium.com/implementing-a-wisdom-engine-for-personal-knowledge-management-3c76b8d8f760
Favicon
How to Use ChatGPT and Zapier to Create a Personal Assistant Integrating Google Calendar, Gmail, Notion, and Slack

https://www.linkedin.com/pulse/how-use-chatgpt-zapier-create-personal-assistant-galvez-herrera-zqsge
Favicon
Add human approvals to your Zaps with Slack integration - Zapier

https://zapier.com/blog/slack-approval-for-ai-automation/
Favicon
Building a Slack-&-Notion AI Team Assistant with OpenAI Agents SDK and Smithery | by Micheal Lanham | May, 2025 | Medium

https://medium.com/@Micheal-Lanham/building-a-slack-notion-ai-team-assistant-with-openai-agents-sdk-and-smithery-1f4e638cba24
Favicon
From Assistant to Agent: Governing Autonomous AI | Credo AI

https://www.credo.ai/recourseslongform/from-assistant-to-agent-navigating-the-governance-challenges-of-increasingly-autonomous-ai
Favicon
From Assistant to Agent: Governing Autonomous AI | Credo AI

https://www.credo.ai/recourseslongform/from-assistant-to-agent-navigating-the-governance-challenges-of-increasingly-autonomous-ai
Favicon
Health app's future AI assistant will tell you how to keep fit

https://appleinsider.com/articles/25/03/30/health-apps-future-ai-assistant-will-tell-you-how-to-keep-fit
Favicon
From Assistant to Agent: Governing Autonomous AI | Credo AI

https://www.credo.ai/recourseslongform/from-assistant-to-agent-navigating-the-governance-challenges-of-increasingly-autonomous-ai
Favicon
Add human approvals to your Zaps with Slack integration

https://zapier.com/blog/slack-approval-for-ai-automation/
Favicon
How to Use ChatGPT and Zapier to Create a Personal Assistant Integrating Google Calendar, Gmail, Notion, and Slack

https://www.linkedin.com/pulse/how-use-chatgpt-zapier-create-personal-assistant-galvez-herrera-zqsge
All Sources
Favicon
asksensay.medium
Favicon
linkedin
Favicon
zapier
Favicon
medium
Favicon
credo
Favicon
appleinsider